{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2CtJqDv8BXD"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbR_b_hg8JvY"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEmo8cZU8L59"
   },
   "source": [
    "## Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 30306,
     "status": "ok",
     "timestamp": 1594583025466,
     "user": {
      "displayName": "Vaishnavi Rajagopal",
      "photoUrl": "",
      "userId": "12495969037198368701"
     },
     "user_tz": -330
    },
    "id": "utYa-hBM_IL0",
    "outputId": "b69d6282-6588-4255-d8aa-3dae730aa3ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1815,
     "status": "ok",
     "timestamp": 1594583793244,
     "user": {
      "displayName": "Vaishnavi Rajagopal",
      "photoUrl": "",
      "userId": "12495969037198368701"
     },
     "user_tz": -330
    },
    "id": "hSKEHalq_Iu_"
   },
   "outputs": [],
   "source": [
    "data_path = 'gdrive/My Drive/MIDS/NLP_w266/w266_Final_Project/Data'\n",
    "project_path = 'gdrive/My Drive/MIDS/NLP_w266/w266_Final_Project'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY4xlNXo_Nne"
   },
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPpb7d_R_RCm"
   },
   "outputs": [],
   "source": [
    "# Pre-process\n",
    "\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr|\\d)[.]\"\n",
    "suffixes = \"(www|WWW|Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(WWW|www|Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov|\\d)\"\n",
    "\n",
    "def preprocess(text):\n",
    "    text = \" \" + str(text) + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    # contraction \n",
    "    # specific\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "\n",
    "    # general\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "\n",
    "    # Numerical\n",
    "    text = re.sub(r\"[0-9]+([.][0-9]+)\", 'DECIMAL', text)\n",
    "    text = re.sub(r\"[0-9]+\", 'INTEGER', text)\n",
    "\n",
    "    # Currency\n",
    "    text = re.sub(r'\\$', 'USD ', text)\n",
    "    text = re.sub(r'\\%', ' PERCENTSIGN', text)\n",
    "\n",
    "    # to make it easy to split sentence. \n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"PhD\")\n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWmL-WoNfhoH"
   },
   "outputs": [],
   "source": [
    "def split_into_sentences(text):    \n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences if '<' not in s and '(' not in s]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "phH1T5SZ_X4q"
   },
   "outputs": [],
   "source": [
    "## creating a text file with one sentence each and separator inbetween transcripts \n",
    "def sentence_text_file_construct (transcript, scope = 'PR'):\n",
    "\n",
    "    sentence_list = []\n",
    "\n",
    "    # select only relevant component type\n",
    "    if scope == 'PR':\n",
    "        df = transcript[transcript.transcriptcomponenttypeid.isin([2,5])]\n",
    "    elif scope == 'QA':\n",
    "        df = transcript[transcript.transcriptcomponenttypeid.isin([3,4,6,8])]\n",
    "    else: \n",
    "        df = transcript[~transcript.transcriptcomponenttypeid.isin([1,7])]\n",
    "\n",
    "    df = df[['transcriptid', 'transcriptcomponentid', 'componentorder','componenttext']]\n",
    "    ordered_df = df.groupby('transcriptid').apply(pd.DataFrame.sort_values, 'componentorder')\n",
    "\n",
    "    for i in df.transcriptid.unique():\n",
    "\n",
    "        trans_text = ordered_df.loc[i].componenttext.apply(lambda x: split_into_sentences(preprocess(x)))\n",
    "        for t in trans_text:\n",
    "            for z in t:\n",
    "                sentence_list += [z]\n",
    "        sentence_list += ['\\n']\n",
    "\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRpFNkTnD8Hh"
   },
   "outputs": [],
   "source": [
    "# function to write to file \n",
    "def write_to_file (list_of_text, file):\n",
    "    with open (file, 'w+') as f:\n",
    "        for i in list_of_text:\n",
    "            f.write(\"%s\\n\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2963088,
     "status": "ok",
     "timestamp": 1593395245395,
     "user": {
      "displayName": "Ying Hua",
      "photoUrl": "",
      "userId": "06288189407162626657"
     },
     "user_tz": 420
    },
    "id": "_OmC9fRKGKac",
    "outputId": "b9af1e52-9e9c-4108-be4a-5cbc5f0ab48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive/My Drive/big_data/transcripts_unzipped/transcripts/transcript_key_dev_link.csv\n"
     ]
    }
   ],
   "source": [
    "# Pulling everything together\n",
    "input_file_s =  project_path + 'finBERT/raw_input_file.txt'\n",
    "for f in glob.glob(data_path +'*.csv'):\n",
    "    transcripts = pd.read_csv(f)\n",
    "    try:\n",
    "        sentence_list = sentence_text_file_construct (transcripts, scope = 'ALL')\n",
    "        write_to_file (sentence_list, input_file_s)\n",
    "    except:\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I_uMT0aZQba5"
   },
   "outputs": [],
   "source": [
    "# with open(input_file_s, \"r\") as f:\n",
    "#     text = [sentence_text_file_constructnext(f) for x in range (500)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5SBIBL8ciOa"
   },
   "outputs": [],
   "source": [
    "# write_to_file (text, project_path + 'preprocessing_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fM6poE8jJsRo"
   },
   "outputs": [],
   "source": [
    "with open(input_file_s, \"r\") as f:\n",
    "    text = [(next(f)) for x in range (500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P9wq3eO3OGuf"
   },
   "outputs": [],
   "source": [
    "input_file_s =  '/content/drive/My Drive/w266_project/finBERT/raw_input_file.txt'\n",
    "with open(input_file_s, \"r\") as f:\n",
    "    n = sum(1 for i in f)\n",
    "with open(input_file_s, \"r\") as f:\n",
    "    w_by_s = [len(next(f).split()) for x in range(n)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1593437171900,
     "user": {
      "displayName": "Ying Hua",
      "photoUrl": "",
      "userId": "06288189407162626657"
     },
     "user_tz": 420
    },
    "id": "qp5FokVrObMJ",
    "outputId": "a80f15b9-753f-4ba3-db64-4a49e4375e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains  3611161  of sentences.\n",
      "The data contains  69391787  of words.\n",
      "Average sentence length 19.21592169388183 .\n",
      "Max sentence length 369 .\n"
     ]
    }
   ],
   "source": [
    "words = sum(w_by_s)\n",
    "avg_words = words/len(w_by_s)\n",
    "max_words = max(w_by_s)\n",
    "print ('The data contains ', n, ' of sentences.')\n",
    "print ('The data contains ', words, ' of words.')\n",
    "print ('Average sentence length', avg_words,'.')\n",
    "print ('Max sentence length', max_words,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1406038,
     "status": "ok",
     "timestamp": 1593438707605,
     "user": {
      "displayName": "Ying Hua",
      "photoUrl": "",
      "userId": "06288189407162626657"
     },
     "user_tz": 420
    },
    "id": "Wg2UfNJmzB-h",
    "outputId": "af1a765d-762f-45f0-b135-5d38d9c755f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdrive/My Drive/big_data/transcripts_unzipped/transcripts/transcript_key_dev_link.csv\n"
     ]
    }
   ],
   "source": [
    "# Seperate file with just prepared remarks \n",
    "input_file_s =  project_path + 'finBERT/raw_input_file_pr.txt'\n",
    "for f in glob.glob(data_path +'*.csv'):\n",
    "    transcripts = pd.read_csv(f)\n",
    "    try:\n",
    "        sentence_list = sentence_text_file_construct (transcripts, scope = 'PR')\n",
    "        write_to_file (sentence_list, input_file_s)\n",
    "    except:\n",
    "        print (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "moUx0NzEQ6rM"
   },
   "outputs": [],
   "source": [
    "input_file_s ='/content/gdrive/My Drive/w266_project/finBERT/raw_input_file_pr.txt'\n",
    "with open(input_file_s, \"r\") as f:\n",
    "    n = sum(1 for i in f)\n",
    "with open(input_file_s, \"r\") as f:\n",
    "    w_by_s = [len(next(f).split()) for x in range(n)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1314,
     "status": "ok",
     "timestamp": 1593438968266,
     "user": {
      "displayName": "Ying Hua",
      "photoUrl": "",
      "userId": "06288189407162626657"
     },
     "user_tz": 420
    },
    "id": "Dl6aQQxDVsNA",
    "outputId": "5ddb5a42-dcdb-480d-95cf-9953809482ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains  1429618  of sentences.\n",
      "The data contains  30026157  of words.\n",
      "Average sentence length 21.002923158494088 .\n",
      "Max sentence length 369 .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = sum(w_by_s)\n",
    "avg_words = words/len(w_by_s)\n",
    "max_words = max(w_by_s)\n",
    "print ('The data contains ', n, ' of sentences.')\n",
    "print ('The data contains ', words, ' of words.')\n",
    "print ('Average sentence length', avg_words,'.')\n",
    "print ('Max sentence length', max_words,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FFxYi2hXRQv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_Data_Prep.ipynb",
   "provenance": [
    {
     "file_id": "1jDP4SYt2EXomnJ54OE2Yc4Bg5KheAweo",
     "timestamp": 1594582775046
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
