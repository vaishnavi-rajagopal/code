{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_Data_Prep.ipynb","provenance":[{"file_id":"1jDP4SYt2EXomnJ54OE2Yc4Bg5KheAweo","timestamp":1594582775046}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k2CtJqDv8BXD","colab_type":"text"},"source":["## Importing Libraries"]},{"cell_type":"code","metadata":{"id":"UbR_b_hg8JvY","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import re\n","import glob"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fEmo8cZU8L59","colab_type":"text"},"source":["## Mounting Google Drive"]},{"cell_type":"code","metadata":{"id":"utYa-hBM_IL0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1594583025466,"user_tz":-330,"elapsed":30306,"user":{"displayName":"Vaishnavi Rajagopal","photoUrl":"","userId":"12495969037198368701"}},"outputId":"b69d6282-6588-4255-d8aa-3dae730aa3ea"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hSKEHalq_Iu_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594583793244,"user_tz":-330,"elapsed":1815,"user":{"displayName":"Vaishnavi Rajagopal","photoUrl":"","userId":"12495969037198368701"}}},"source":["data_path = 'gdrive/My Drive/MIDS/NLP_w266/w266_Final_Project/Data'\n","project_path = 'gdrive/My Drive/MIDS/NLP_w266/w266_Final_Project'"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zY4xlNXo_Nne","colab_type":"text"},"source":["## Data Processing"]},{"cell_type":"code","metadata":{"id":"PPpb7d_R_RCm","colab_type":"code","colab":{}},"source":["# Pre-process\n","\n","alphabets= \"([A-Za-z])\"\n","prefixes = \"(Mr|St|Mrs|Ms|Dr|\\d)[.]\"\n","suffixes = \"(www|WWW|Inc|Ltd|Jr|Sr|Co)\"\n","starters = \"(WWW|www|Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n","acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n","websites = \"[.](com|net|org|io|gov|\\d)\"\n","\n","def preprocess(text):\n","    text = \" \" + str(text) + \"  \"\n","    text = text.replace(\"\\n\",\" \")\n","    # contraction \n","    # specific\n","    text = re.sub(r\"won\\'t\", \"will not\", text)\n","    text = re.sub(r\"can\\'t\", \"can not\", text)\n","\n","    # general\n","    text = re.sub(r\"n\\'t\", \" not\", text)\n","    text = re.sub(r\"\\'re\", \" are\", text)\n","    text = re.sub(r\"\\'s\", \" is\", text)\n","    text = re.sub(r\"\\'d\", \" would\", text)\n","    text = re.sub(r\"\\'ll\", \" will\", text)\n","    text = re.sub(r\"\\'t\", \" not\", text)\n","    text = re.sub(r\"\\'ve\", \" have\", text)\n","    text = re.sub(r\"\\'m\", \" am\", text)\n","\n","    # Numerical\n","    text = re.sub(r\"[0-9]+([.][0-9]+)\", 'DECIMAL', text)\n","    text = re.sub(r\"[0-9]+\", 'INTEGER', text)\n","\n","    # Currency\n","    text = re.sub(r'\\$', 'USD ', text)\n","    text = re.sub(r'\\%', ' PERCENTSIGN', text)\n","\n","    # to make it easy to split sentence. \n","    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n","    text = re.sub(websites,\"<prd>\\\\1\",text)\n","    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"PhD\")\n","    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n","    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n","    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n","    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n","    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n","    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n","    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n","    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n","    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n","    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n","    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n","    text = text.replace(\".\",\".<stop>\")\n","    text = text.replace(\"?\",\"?<stop>\")\n","    text = text.replace(\"!\",\"!<stop>\")\n","    text = text.replace(\"<prd>\",\".\")\n","\n","    return text\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWmL-WoNfhoH","colab_type":"code","colab":{}},"source":["def split_into_sentences(text):    \n","    sentences = text.split(\"<stop>\")\n","    sentences = sentences[:-1]\n","    sentences = [s.strip() for s in sentences if '<' not in s and '(' not in s]\n","    return sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"phH1T5SZ_X4q","colab_type":"code","colab":{}},"source":["## creating a text file with one sentence each and separator inbetween transcripts \n","def sentence_text_file_construct (transcript, scope = 'PR'):\n","\n","    sentence_list = []\n","\n","    # select only relevant component type\n","    if scope == 'PR':\n","        df = transcript[transcript.transcriptcomponenttypeid.isin([2,5])]\n","    elif scope == 'QA':\n","        df = transcript[transcript.transcriptcomponenttypeid.isin([3,4,6,8])]\n","    else: \n","        df = transcript[~transcript.transcriptcomponenttypeid.isin([1,7])]\n","\n","    df = df[['transcriptid', 'transcriptcomponentid', 'componentorder','componenttext']]\n","    ordered_df = df.groupby('transcriptid').apply(pd.DataFrame.sort_values, 'componentorder')\n","\n","    for i in df.transcriptid.unique():\n","\n","        trans_text = ordered_df.loc[i].componenttext.apply(lambda x: split_into_sentences(preprocess(x)))\n","        for t in trans_text:\n","            for z in t:\n","                sentence_list += [z]\n","        sentence_list += ['\\n']\n","\n","    return sentence_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YRpFNkTnD8Hh","colab_type":"code","colab":{}},"source":["# function to write to file \n","def write_to_file (list_of_text, file):\n","    with open (file, 'w+') as f:\n","        for i in list_of_text:\n","            f.write(\"%s\\n\" % i)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_OmC9fRKGKac","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593395245395,"user_tz":420,"elapsed":2963088,"user":{"displayName":"Ying Hua","photoUrl":"","userId":"06288189407162626657"}},"outputId":"b9af1e52-9e9c-4108-be4a-5cbc5f0ab48f"},"source":["# Pulling everything together\n","input_file_s =  project_path + 'finBERT/raw_input_file.txt'\n","for f in glob.glob(data_path +'*.csv'):\n","    transcripts = pd.read_csv(f)\n","    try:\n","        sentence_list = sentence_text_file_construct (transcripts, scope = 'ALL')\n","        write_to_file (sentence_list, input_file_s)\n","    except:\n","        print (f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gdrive/My Drive/big_data/transcripts_unzipped/transcripts/transcript_key_dev_link.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I_uMT0aZQba5","colab_type":"code","colab":{}},"source":["# with open(input_file_s, \"r\") as f:\n","#     text = [sentence_text_file_constructnext(f) for x in range (500)]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K5SBIBL8ciOa","colab_type":"code","colab":{}},"source":["# write_to_file (text, project_path + 'preprocessing_test.txt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fM6poE8jJsRo","colab_type":"code","colab":{}},"source":["with open(input_file_s, \"r\") as f:\n","    text = [(next(f)) for x in range (500)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9wq3eO3OGuf","colab_type":"code","colab":{}},"source":["input_file_s =  '/content/drive/My Drive/w266_project/finBERT/raw_input_file.txt'\n","with open(input_file_s, \"r\") as f:\n","    n = sum(1 for i in f)\n","with open(input_file_s, \"r\") as f:\n","    w_by_s = [len(next(f).split()) for x in range(n)]\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qp5FokVrObMJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1593437171900,"user_tz":420,"elapsed":469,"user":{"displayName":"Ying Hua","photoUrl":"","userId":"06288189407162626657"}},"outputId":"a80f15b9-753f-4ba3-db64-4a49e4375e2d"},"source":["words = sum(w_by_s)\n","avg_words = words/len(w_by_s)\n","max_words = max(w_by_s)\n","print ('The data contains ', n, ' of sentences.')\n","print ('The data contains ', words, ' of words.')\n","print ('Average sentence length', avg_words,'.')\n","print ('Max sentence length', max_words,'.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The data contains  3611161  of sentences.\n","The data contains  69391787  of words.\n","Average sentence length 19.21592169388183 .\n","Max sentence length 369 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wg2UfNJmzB-h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593438707605,"user_tz":420,"elapsed":1406038,"user":{"displayName":"Ying Hua","photoUrl":"","userId":"06288189407162626657"}},"outputId":"af1a765d-762f-45f0-b135-5d38d9c755f4"},"source":["# Seperate file with just prepared remarks \n","input_file_s =  project_path + 'finBERT/raw_input_file_pr.txt'\n","for f in glob.glob(data_path +'*.csv'):\n","    transcripts = pd.read_csv(f)\n","    try:\n","        sentence_list = sentence_text_file_construct (transcripts, scope = 'PR')\n","        write_to_file (sentence_list, input_file_s)\n","    except:\n","        print (f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["gdrive/My Drive/big_data/transcripts_unzipped/transcripts/transcript_key_dev_link.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"moUx0NzEQ6rM","colab_type":"code","colab":{}},"source":["input_file_s ='/content/gdrive/My Drive/w266_project/finBERT/raw_input_file_pr.txt'\n","with open(input_file_s, \"r\") as f:\n","    n = sum(1 for i in f)\n","with open(input_file_s, \"r\") as f:\n","    w_by_s = [len(next(f).split()) for x in range(n)]\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dl6aQQxDVsNA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1593438968266,"user_tz":420,"elapsed":1314,"user":{"displayName":"Ying Hua","photoUrl":"","userId":"06288189407162626657"}},"outputId":"5ddb5a42-dcdb-480d-95cf-9953809482ce"},"source":["\n","words = sum(w_by_s)\n","avg_words = words/len(w_by_s)\n","max_words = max(w_by_s)\n","print ('The data contains ', n, ' of sentences.')\n","print ('The data contains ', words, ' of words.')\n","print ('Average sentence length', avg_words,'.')\n","print ('Max sentence length', max_words,'.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The data contains  1429618  of sentences.\n","The data contains  30026157  of words.\n","Average sentence length 21.002923158494088 .\n","Max sentence length 369 .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-FFxYi2hXRQv","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}